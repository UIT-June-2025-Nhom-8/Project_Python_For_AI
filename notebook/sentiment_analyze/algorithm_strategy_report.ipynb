{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ac4b7c",
   "metadata": {},
   "source": [
    "# Báo Cáo Chiến Lược Thực Thi Pipeline Các Thuật Toán Sentiment Analysis\n",
    "\n",
    "## Mục Lục\n",
    "1. [Tổng Quan Project](#1-tổng-quan-project)\n",
    "2. [Kiến Trúc Pipeline](#2-kiến-trúc-pipeline)\n",
    "3. [Chiến Lược Xử Lý Dữ Liệu](#3-chiến-lược-xử-lý-dữ-liệu)\n",
    "4. [So Sánh Các Thuật Toán](#4-so-sánh-các-thuật-toán)\n",
    "4. [Cấu Hình Tối Ưu](#5-cấu-hình-tối-ưu)\n",
    "6. [Kết Quả Thực Nghiệm](#6-kết-quả-thực-nghiệm)\n",
    "7. [Khuyến Nghị](#7-khuyến-nghị)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Tổng Quan Project\n",
    "\n",
    "Project này thực hiện **Sentiment Analysis** trên dataset Amazon Reviews với mục tiêu:\n",
    "- Phân loại sentiment (positive/negative) của reviews\n",
    "- So sánh hiệu suất của 3 thuật toán Machine Learning\n",
    "- Tối ưu hóa pipeline để đạt độ chính xác cao nhất\n",
    "\n",
    "### Đặc điểm Dataset\n",
    "- **Nguồn**: Amazon Review Polarity Dataset từ Kaggle\n",
    "- **Kích thước**: Có thể điều chỉnh (1000-40000 samples training)\n",
    "- **Định dạng**: CSV với cột text và label (1: positive, 2: negative)\n",
    "- **Thách thức**: Text không cấu trúc, nhiễu, độ dài khác nhau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91f6c54",
   "metadata": {},
   "source": [
    "## 2. Kiến Trúc Pipeline\n",
    "\n",
    "### 2.1 Workflow Tổng Thể\n",
    "\n",
    "```\n",
    "┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐\n",
    "│   Data Loading  │───▶│  Preprocessing   │───▶│  Feature        │\n",
    "│   (Kaggle/Local)│    │  (Text Cleaning) │    │  Extraction     │\n",
    "└─────────────────┘    └──────────────────┘    │  (TF-IDF)       │\n",
    "                                               └─────────────────┘\n",
    "                                                         │\n",
    "┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐\n",
    "│   Model         │◀───│   Model          │◀───│   Model         │\n",
    "│   Evaluation    │    │   Training       │    │   Selection     │\n",
    "└─────────────────┘    └──────────────────┘    └─────────────────┘\n",
    "```\n",
    "\n",
    "### 2.2 Các Thành Phần Chính\n",
    "\n",
    "| Component | File | Chức năng |\n",
    "|-----------|------|-----------|\n",
    "| **Data Loader** | `kaggle_data_loader.py`, `local_data_loader.py` | Tải và chuẩn bị dữ liệu |\n",
    "| **Preprocessor** | `pre_processor.py` | Làm sạch và chuẩn hóa text |\n",
    "| **Feature Extractor** | `tf_idf_vectorizer.py` | Chuyển đổi text thành vector |\n",
    "| **Model Trainers** | `*_classifier.py` | Huấn luyện các thuật toán |\n",
    "| **Pipeline Controller** | `main_modal_traning_focus.py` | Điều phối toàn bộ quá trình |\n",
    "| **Config Manager** | `config_loader.py` | Quản lý cấu hình |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e9610",
   "metadata": {},
   "source": [
    "## 3. Chiến Lược Xử Lý Dữ Liệu\n",
    "\n",
    "### 3.1 Text Preprocessing Strategy\n",
    "\n",
    "**Mục tiêu**: Tối ưu hóa chất lượng text để cải thiện hiệu suất model\n",
    "\n",
    "#### 3.1.1 Quy Trình Preprocessing\n",
    "```python\n",
    "# Workflow trong PreProcessor.preprocess_for_sentiment()\n",
    "Text Input → Text Cleaning → Tokenization → Stopword Removal → Lemmatization → Normalization\n",
    "```\n",
    "\n",
    "#### 3.1.2 Các Kỹ Thuật Áp Dụng\n",
    "\n",
    "| Bước | Kỹ thuật | Lý do |\n",
    "|------|----------|-------|\n",
    "| **Text Cleaning** | Loại bỏ HTML, URL, ký tự đặc biệt | Giảm nhiễu, chuẩn hóa input |\n",
    "| **Preserve Negation** | Giữ lại \"not\", \"no\", \"never\" | Quan trọng cho sentiment analysis |\n",
    "| **Lemmatization** | Đưa về dạng gốc của từ | Giảm số lượng features, tăng tính tổng quát |\n",
    "| **Lowercase** | Chuyển về chữ thường | Tránh phân biệt chữ hoa/thường |\n",
    "| **Remove Duplicates** | Loại bỏ text trùng lặp | Tránh overfitting |\n",
    "\n",
    "#### 3.1.3 Sentiment-Aware Features\n",
    "- **Preserving Negation**: Đặc biệt quan trọng cho sentiment\n",
    "- **Custom Stopwords**: Loại bỏ từ không mang ý nghĩa sentiment\n",
    "- **Text Length Control**: Xử lý reviews quá ngắn/dài"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a2e322",
   "metadata": {},
   "source": [
    "## 4. Cấu Hình Tối Ưu\n",
    "\n",
    "### 4.1 Configuration Strategy\n",
    "\n",
    "Project sử dụng **JSON-based configuration system** để:\n",
    "- Dễ dàng thay đổi hyperparameters\n",
    "- So sánh multiple configurations\n",
    "- Reproducible experiments\n",
    "- Parallel testing của different strategies\n",
    "\n",
    "### 4.2 Các Loại Configuration\n",
    "\n",
    "#### 4.2.1 Balanced Configuration\n",
    "- **Mục tiêu**: Cân bằng giữa accuracy và training time\n",
    "- **Dataset size**: Medium (5000-10000 samples)\n",
    "- **Training time**: 5-10 phút\n",
    "- **Use case**: Development và testing\n",
    "\n",
    "#### 4.2.2 Accuracy Optimized Configuration  \n",
    "- **Mục tiêu**: Đạt accuracy cao nhất có thể\n",
    "- **Dataset size**: Large (20000+ samples)\n",
    "- **Training time**: 15-30 phút\n",
    "- **Use case**: Final model cho production\n",
    "\n",
    "#### 4.2.3 Speed Optimized Configuration\n",
    "- **Mục tiêu**: Training nhanh nhất\n",
    "- **Dataset size**: Small (1000-2000 samples)\n",
    "- **Training time**: 1-3 phút\n",
    "- **Use case**: Rapid prototyping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966fd08b",
   "metadata": {},
   "source": [
    "## 4.3 Chi Tiết Hyperparameters cho Từng Thuật Toán\n",
    "\n",
    "### 4.3.1 Logistic Regression Parameters\n",
    "\n",
    "#### Core Parameters\n",
    "```python\n",
    "LogisticRegression(\n",
    "    C=1.0,                    # Regularization strength (inverse)\n",
    "    solver='liblinear',       # Optimization algorithm\n",
    "    max_iter=1000,           # Maximum iterations\n",
    "    random_state=42          # For reproducibility\n",
    ")\n",
    "```\n",
    "\n",
    "**Giải thích chi tiết:**\n",
    "\n",
    "| Parameter | Ý nghĩa | Giá trị khuyến nghị | Tác động |\n",
    "|-----------|---------|-------------------|----------|\n",
    "| **C** | Độ mạnh regularization (nghịch đảo) | 0.1 - 10.0 | • C nhỏ: Regularization mạnh, tránh overfitting<br>• C lớn: Ít regularization, có thể overfit |\n",
    "| **solver** | Thuật toán tối ưu hóa | 'liblinear', 'lbfgs' | • 'liblinear': Tốt cho small dataset<br>• 'lbfgs': Tốt cho large dataset |\n",
    "| **max_iter** | Số lần lặp tối đa | 1000-5000 | • Quá thấp: Model chưa converge<br>• Quá cao: Tốn thời gian training |\n",
    "| **penalty** | Loại regularization | 'l1', 'l2' | • L1: Feature selection<br>• L2: Shrink coefficients |\n",
    "\n",
    "#### Advanced Parameters\n",
    "```python\n",
    "# Thêm các parameters nâng cao\n",
    "LogisticRegression(\n",
    "    penalty='l2',             # L1/L2 regularization\n",
    "    class_weight='balanced',  # Handle imbalanced data\n",
    "    dual=False,              # Primal vs dual formulation\n",
    "    fit_intercept=True       # Add bias term\n",
    ")\n",
    "```\n",
    "\n",
    "### 4.3.2 Random Forest Parameters\n",
    "\n",
    "#### Core Parameters\n",
    "```python\n",
    "RandomForestClassifier(\n",
    "    n_estimators=100,        # Số cây trong forest\n",
    "    max_depth=None,          # Độ sâu tối đa của cây\n",
    "    min_samples_split=2,     # Số samples tối thiểu để split\n",
    "    min_samples_leaf=1,      # Số samples tối thiểu ở leaf\n",
    "    random_state=42\n",
    ")\n",
    "```\n",
    "\n",
    "**Giải thích chi tiết:**\n",
    "\n",
    "| Parameter | Ý nghĩa | Giá trị khuyến nghị | Tác động |\n",
    "|-----------|---------|-------------------|----------|\n",
    "| **n_estimators** | Số cây trong ensemble | 50-200 | • Nhiều cây: Accuracy cao hơn, training lâu hơn<br>• Ít cây: Training nhanh, có thể underfit |\n",
    "| **max_depth** | Độ sâu tối đa của cây | 10-20 hoặc None | • Sâu: Có thể overfit<br>• Nông: Có thể underfit<br>• None: Cây phát triển tự nhiên |\n",
    "| **min_samples_split** | Min samples để split node | 2-10 | • Thấp: Cây chi tiết hơn, có thể overfit<br>• Cao: Cây đơn giản hơn, tránh overfit |\n",
    "| **min_samples_leaf** | Min samples ở leaf node | 1-5 | • Thấp: Leaf có ít samples, chi tiết<br>• Cao: Leaf có nhiều samples, tổng quát |\n",
    "\n",
    "#### Advanced Parameters\n",
    "```python\n",
    "RandomForestClassifier(\n",
    "    max_features='sqrt',      # Số features random cho mỗi split\n",
    "    bootstrap=True,          # Bootstrap sampling\n",
    "    oob_score=True,          # Out-of-bag score\n",
    "    class_weight='balanced', # Handle imbalanced classes\n",
    "    criterion='gini'         # Splitting criterion\n",
    ")\n",
    "```\n",
    "\n",
    "**Advanced Parameters Explained:**\n",
    "\n",
    "| Parameter | Ý nghĩa | Options | Tác động |\n",
    "|-----------|---------|---------|----------|\n",
    "| **max_features** | Features xem xét cho mỗi split | 'sqrt', 'log2', int, float | • 'sqrt': √n_features, good default<br>• 'log2': log₂(n_features)<br>• int: Exact number |\n",
    "| **criterion** | Hàm đo độ không thuần khiết | 'gini', 'entropy' | • 'gini': Nhanh hơn<br>• 'entropy': Information gain |\n",
    "| **bootstrap** | Sampling với replacement | True/False | • True: Diversity trong training<br>• False: Sử dụng toàn bộ dataset |\n",
    "\n",
    "### 4.3.3 Gradient Boosting Parameters\n",
    "\n",
    "#### Core Parameters\n",
    "```python\n",
    "GradientBoostingClassifier(\n",
    "    n_estimators=100,        # Số boosting stages\n",
    "    learning_rate=0.1,       # Tốc độ học\n",
    "    max_depth=3,            # Độ sâu của weak learners\n",
    "    subsample=1.0,          # Fraction samples cho training\n",
    "    random_state=42\n",
    ")\n",
    "```\n",
    "\n",
    "**Giải thích chi tiết:**\n",
    "\n",
    "| Parameter | Ý nghĩa | Giá trị khuyến nghị | Tác động |\n",
    "|-----------|---------|-------------------|----------|\n",
    "| **n_estimators** | Số boosting rounds | 50-200 | • Nhiều: Có thể overfit nhưng accuracy cao<br>• Ít: Có thể underfit |\n",
    "| **learning_rate** | Shrinkage rate | 0.01-0.3 | • Thấp: Training chậm, cần nhiều estimators<br>• Cao: Training nhanh, dễ overfit |\n",
    "| **max_depth** | Độ sâu weak learner | 3-6 | • Shallow: Simple learners, tránh overfit<br>• Deep: Complex learners, có thể overfit |\n",
    "| **subsample** | Tỷ lệ samples training | 0.5-1.0 | • < 1.0: Stochastic gradient boosting<br>• = 1.0: Deterministic boosting |\n",
    "\n",
    "#### Advanced Parameters\n",
    "```python\n",
    "GradientBoostingClassifier(\n",
    "    loss='deviance',         # Loss function\n",
    "    min_samples_split=2,     # Min samples to split\n",
    "    min_samples_leaf=1,      # Min samples at leaf\n",
    "    max_features=None,       # Features to consider\n",
    "    validation_fraction=0.1, # Fraction for early stopping\n",
    "    n_iter_no_change=5      # Early stopping patience\n",
    ")\n",
    "```\n",
    "\n",
    "**Advanced Parameters Explained:**\n",
    "\n",
    "| Parameter | Ý nghĩa | Options | Tác động |\n",
    "|-----------|---------|---------|----------|\n",
    "| **loss** | Hàm loss | 'deviance', 'exponential' | • 'deviance': Logistic regression loss<br>• 'exponential': AdaBoost loss |\n",
    "| **validation_fraction** | Data cho early stopping | 0.1-0.2 | • Monitor overfitting<br>• Automatic stopping |\n",
    "| **warm_start** | Incremental training | True/False | • True: Có thể thêm estimators<br>• False: Training từ đầu |\n",
    "\n",
    "### 4.3.4 TF-IDF Vectorizer Parameters\n",
    "\n",
    "#### Core Parameters  \n",
    "```python\n",
    "TfidfVectorizer(\n",
    "    max_features=10000,      # Số features tối đa\n",
    "    ngram_range=(1, 2),      # N-gram range\n",
    "    min_df=2,               # Min document frequency\n",
    "    max_df=0.95,            # Max document frequency\n",
    "    stop_words='english'     # Stopwords removal\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
