{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ac4b7c",
   "metadata": {},
   "source": [
    "# Báo Cáo Chiến Lược Thực Thi Pipeline Các Thuật Toán Sentiment Analysis\n",
    "\n",
    "## Mục Lục\n",
    "1. [Tổng Quan Project](#1-tổng-quan-project)\n",
    "2. [Kiến Trúc Pipeline](#2-kiến-trúc-pipeline)\n",
    "3. [Chiến Lược Xử Lý Dữ Liệu](#3-chiến-lược-xử-lý-dữ-liệu)\n",
    "4. [So Sánh Các Thuật Toán](#4-so-sánh-các-thuật-toán)\n",
    "5. [Cấu Hình Tối Ưu](#5-cấu-hình-tối-ưu)\n",
    "6. [Kết Quả Thực Nghiệm](#6-kết-quả-thực-nghiệm)\n",
    "7. [Khuyến Nghị](#7-khuyến-nghị)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Tổng Quan Project\n",
    "\n",
    "Project này thực hiện **Sentiment Analysis** trên dataset Amazon Reviews với mục tiêu:\n",
    "- Phân loại sentiment (positive/negative) của reviews\n",
    "- So sánh hiệu suất của 3 thuật toán Machine Learning\n",
    "- Tối ưu hóa pipeline để đạt độ chính xác cao nhất\n",
    "\n",
    "### Đặc điểm Dataset\n",
    "- **Nguồn**: Amazon Review Polarity Dataset từ Kaggle\n",
    "- **Kích thước**: Có thể điều chỉnh (1000-40000 samples training)\n",
    "- **Định dạng**: CSV với cột text và label (1: positive, 2: negative)\n",
    "- **Thách thức**: Text không cấu trúc, nhiễu, độ dài khác nhau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91f6c54",
   "metadata": {},
   "source": [
    "## 2. Kiến Trúc Pipeline\n",
    "\n",
    "### 2.1 Workflow Tổng Thể\n",
    "\n",
    "```\n",
    "┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐\n",
    "│   Data Loading  │───▶│  Preprocessing   │───▶│  Feature        │\n",
    "│   (Kaggle/Local)│    │  (Text Cleaning) │    │  Extraction     │\n",
    "└─────────────────┘    └──────────────────┘    │  (TF-IDF)       │\n",
    "                                               └─────────────────┘\n",
    "                                                         │\n",
    "┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐\n",
    "│   Model         │◀───│   Model          │◀───│   Model         │\n",
    "│   Evaluation    │    │   Training       │    │   Selection     │\n",
    "└─────────────────┘    └──────────────────┘    └─────────────────┘\n",
    "```\n",
    "\n",
    "### 2.2 Các Thành Phần Chính\n",
    "\n",
    "| Component | File | Chức năng |\n",
    "|-----------|------|-----------|\n",
    "| **Data Loader** | `kaggle_data_loader.py`, `local_data_loader.py` | Tải và chuẩn bị dữ liệu |\n",
    "| **Preprocessor** | `pre_processor.py` | Làm sạch và chuẩn hóa text |\n",
    "| **Feature Extractor** | `tf_idf_vectorizer.py` | Chuyển đổi text thành vector |\n",
    "| **Model Trainers** | `*_classifier.py` | Huấn luyện các thuật toán |\n",
    "| **Pipeline Controller** | `main_modal_traning_focus.py` | Điều phối toàn bộ quá trình |\n",
    "| **Config Manager** | `config_loader.py` | Quản lý cấu hình |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e9610",
   "metadata": {},
   "source": [
    "## 3. Chiến Lược Xử Lý Dữ Liệu\n",
    "\n",
    "### 3.1 Text Preprocessing Strategy\n",
    "\n",
    "**Mục tiêu**: Tối ưu hóa chất lượng text để cải thiện hiệu suất model\n",
    "\n",
    "#### 3.1.1 Quy Trình Preprocessing\n",
    "```python\n",
    "# Workflow trong PreProcessor.preprocess_for_sentiment()\n",
    "Text Input → Text Cleaning → Tokenization → Stopword Removal → Lemmatization → Normalization\n",
    "```\n",
    "\n",
    "#### 3.1.2 Các Kỹ Thuật Áp Dụng\n",
    "\n",
    "| Bước | Kỹ thuật | Lý do |\n",
    "|------|----------|-------|\n",
    "| **Text Cleaning** | Loại bỏ HTML, URL, ký tự đặc biệt | Giảm nhiễu, chuẩn hóa input |\n",
    "| **Preserve Negation** | Giữ lại \"not\", \"no\", \"never\" | Quan trọng cho sentiment analysis |\n",
    "| **Lemmatization** | Đưa về dạng gốc của từ | Giảm số lượng features, tăng tính tổng quát |\n",
    "| **Lowercase** | Chuyển về chữ thường | Tránh phân biệt chữ hoa/thường |\n",
    "| **Remove Duplicates** | Loại bỏ text trùng lặp | Tránh overfitting |\n",
    "\n",
    "#### 3.1.3 Sentiment-Aware Features\n",
    "- **Preserving Negation**: Đặc biệt quan trọng cho sentiment\n",
    "- **Custom Stopwords**: Loại bỏ từ không mang ý nghĩa sentiment\n",
    "- **Text Length Control**: Xử lý reviews quá ngắn/dài"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8e9cce",
   "metadata": {},
   "source": [
    "## 4. So Sánh Các Thuật Toán\n",
    "\n",
    "### 4.1 Tổng Quan Các Model\n",
    "\n",
    "| Thuật Toán | Ưu Điểm | Nhược Điểm | Phù Hợp Cho |\n",
    "|------------|---------|------------|-------------|\n",
    "| **Logistic Regression** | • Nhanh, đơn giản<br>• Dễ interpret<br>• Ít tham số | • Tuyến tính<br>• Không xử lý tốt non-linear | • Baseline model<br>• Dataset lớn<br>• Real-time prediction |\n",
    "| **Random Forest** | • Xử lý tốt overfitting<br>• Feature importance<br>• Robust với outliers | • Khó interpret<br>• Tốn memory<br>• Có thể overfit với noisy data | • Medium dataset<br>• Feature selection<br>• Balanced performance |\n",
    "| **Gradient Boosting** | • Độ chính xác cao<br>• Flexible<br>• Tốt với imbalanced data | • Dễ overfit<br>• Tốn thời gian training<br>• Nhiều hyperparameters | • High accuracy requirements<br>• Competition<br>• Complex patterns |\n",
    "\n",
    "### 4.2 Chiến Lược Implementation\n",
    "\n",
    "#### 4.2.1 Logistic Regression Strategy\n",
    "```python\n",
    "# Tối ưu cho tốc độ và baseline performance\n",
    "LogisticRegressionAnalyzer:\n",
    "- TF-IDF: max_features=5000-10000\n",
    "- Solver: 'liblinear' cho small dataset, 'lbfgs' cho large\n",
    "- Regularization: L2 để tránh overfitting\n",
    "```\n",
    "\n",
    "#### 4.2.2 Random Forest Strategy  \n",
    "```python\n",
    "# Tối ưu cho robustness và feature importance\n",
    "RandomForestAnalyzer:\n",
    "- n_estimators: 100-200 (balance giữa performance và speed)\n",
    "- max_depth: 10-20 để tránh overfitting\n",
    "- min_samples_split: 5-10 để ensure sample size\n",
    "```\n",
    "\n",
    "#### 4.2.3 Gradient Boosting Strategy\n",
    "```python\n",
    "# Tối ưu cho accuracy cao nhất\n",
    "GradientBoostingAnalyzer:\n",
    "- n_estimators: 100-200\n",
    "- learning_rate: 0.1-0.2 (moderate để tránh overfitting)\n",
    "- max_depth: 3-6 (shallow trees cho ensemble)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a2e322",
   "metadata": {},
   "source": [
    "## 5. Cấu Hình Tối Ưu\n",
    "\n",
    "### 5.1 Configuration Strategy\n",
    "\n",
    "Project sử dụng **JSON-based configuration system** để:\n",
    "- Dễ dàng thay đổi hyperparameters\n",
    "- So sánh multiple configurations\n",
    "- Reproducible experiments\n",
    "- Parallel testing của different strategies\n",
    "\n",
    "### 5.2 Các Loại Configuration\n",
    "\n",
    "#### 5.2.1 Balanced Configuration\n",
    "- **Mục tiêu**: Cân bằng giữa accuracy và training time\n",
    "- **Dataset size**: Medium (5000-10000 samples)\n",
    "- **Training time**: 5-10 phút\n",
    "- **Use case**: Development và testing\n",
    "\n",
    "#### 5.2.2 Accuracy Optimized Configuration  \n",
    "- **Mục tiêu**: Đạt accuracy cao nhất có thể\n",
    "- **Dataset size**: Large (20000+ samples)\n",
    "- **Training time**: 15-30 phút\n",
    "- **Use case**: Final model cho production\n",
    "\n",
    "#### 5.2.3 Speed Optimized Configuration\n",
    "- **Mục tiêu**: Training nhanh nhất\n",
    "- **Dataset size**: Small (1000-2000 samples)\n",
    "- **Training time**: 1-3 phút\n",
    "- **Use case**: Rapid prototyping\n",
    "\n",
    "### 5.3 Hyperparameter Tuning Strategy\n",
    "\n",
    "#### 5.3.1 TF-IDF Optimization\n",
    "```json\n",
    "{\n",
    "  \"max_features\": [5000, 10000, 20000],\n",
    "  \"ngram_range\": [\"(1,1)\", \"(1,2)\", \"(1,3)\"],\n",
    "  \"min_df\": [2, 5, 10],\n",
    "  \"max_df\": [0.8, 0.9, 0.95]\n",
    "}\n",
    "```\n",
    "\n",
    "#### 5.3.2 Model-Specific Tuning\n",
    "\n",
    "**Logistic Regression**:\n",
    "- C: [0.1, 1.0, 10.0] (regularization strength)\n",
    "- solver: ['liblinear', 'lbfgs']\n",
    "- max_iter: [1000, 2000, 5000]\n",
    "\n",
    "**Random Forest**:\n",
    "- n_estimators: [50, 100, 200]\n",
    "- max_depth: [10, 15, 20, None]\n",
    "- min_samples_split: [2, 5, 10]\n",
    "\n",
    "**Gradient Boosting**:\n",
    "- n_estimators: [100, 150, 200]\n",
    "- learning_rate: [0.05, 0.1, 0.2]\n",
    "- max_depth: [3, 5, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966fd08b",
   "metadata": {},
   "source": [
    "## 4.3 Chi Tiết Hyperparameters cho Từng Thuật Toán\n",
    "\n",
    "### 4.3.1 Logistic Regression Parameters\n",
    "\n",
    "#### Core Parameters\n",
    "```python\n",
    "LogisticRegression(\n",
    "    C=1.0,                    # Regularization strength (inverse)\n",
    "    solver='liblinear',       # Optimization algorithm\n",
    "    max_iter=1000,           # Maximum iterations\n",
    "    random_state=42          # For reproducibility\n",
    ")\n",
    "```\n",
    "\n",
    "**Giải thích chi tiết:**\n",
    "\n",
    "| Parameter | Ý nghĩa | Giá trị khuyến nghị | Tác động |\n",
    "|-----------|---------|-------------------|----------|\n",
    "| **C** | Độ mạnh regularization (nghịch đảo) | 0.1 - 10.0 | • C nhỏ: Regularization mạnh, tránh overfitting<br>• C lớn: Ít regularization, có thể overfit |\n",
    "| **solver** | Thuật toán tối ưu hóa | 'liblinear', 'lbfgs' | • 'liblinear': Tốt cho small dataset<br>• 'lbfgs': Tốt cho large dataset |\n",
    "| **max_iter** | Số lần lặp tối đa | 1000-5000 | • Quá thấp: Model chưa converge<br>• Quá cao: Tốn thời gian training |\n",
    "| **penalty** | Loại regularization | 'l1', 'l2' | • L1: Feature selection<br>• L2: Shrink coefficients |\n",
    "\n",
    "#### Advanced Parameters\n",
    "```python\n",
    "# Thêm các parameters nâng cao\n",
    "LogisticRegression(\n",
    "    penalty='l2',             # L1/L2 regularization\n",
    "    class_weight='balanced',  # Handle imbalanced data\n",
    "    dual=False,              # Primal vs dual formulation\n",
    "    fit_intercept=True       # Add bias term\n",
    ")\n",
    "```\n",
    "\n",
    "### 4.3.2 Random Forest Parameters\n",
    "\n",
    "#### Core Parameters\n",
    "```python\n",
    "RandomForestClassifier(\n",
    "    n_estimators=100,        # Số cây trong forest\n",
    "    max_depth=None,          # Độ sâu tối đa của cây\n",
    "    min_samples_split=2,     # Số samples tối thiểu để split\n",
    "    min_samples_leaf=1,      # Số samples tối thiểu ở leaf\n",
    "    random_state=42\n",
    ")\n",
    "```\n",
    "\n",
    "**Giải thích chi tiết:**\n",
    "\n",
    "| Parameter | Ý nghĩa | Giá trị khuyến nghị | Tác động |\n",
    "|-----------|---------|-------------------|----------|\n",
    "| **n_estimators** | Số cây trong ensemble | 50-200 | • Nhiều cây: Accuracy cao hơn, training lâu hơn<br>• Ít cây: Training nhanh, có thể underfit |\n",
    "| **max_depth** | Độ sâu tối đa của cây | 10-20 hoặc None | • Sâu: Có thể overfit<br>• Nông: Có thể underfit<br>• None: Cây phát triển tự nhiên |\n",
    "| **min_samples_split** | Min samples để split node | 2-10 | • Thấp: Cây chi tiết hơn, có thể overfit<br>• Cao: Cây đơn giản hơn, tránh overfit |\n",
    "| **min_samples_leaf** | Min samples ở leaf node | 1-5 | • Thấp: Leaf có ít samples, chi tiết<br>• Cao: Leaf có nhiều samples, tổng quát |\n",
    "\n",
    "#### Advanced Parameters\n",
    "```python\n",
    "RandomForestClassifier(\n",
    "    max_features='sqrt',      # Số features random cho mỗi split\n",
    "    bootstrap=True,          # Bootstrap sampling\n",
    "    oob_score=True,          # Out-of-bag score\n",
    "    class_weight='balanced', # Handle imbalanced classes\n",
    "    criterion='gini'         # Splitting criterion\n",
    ")\n",
    "```\n",
    "\n",
    "**Advanced Parameters Explained:**\n",
    "\n",
    "| Parameter | Ý nghĩa | Options | Tác động |\n",
    "|-----------|---------|---------|----------|\n",
    "| **max_features** | Features xem xét cho mỗi split | 'sqrt', 'log2', int, float | • 'sqrt': √n_features, good default<br>• 'log2': log₂(n_features)<br>• int: Exact number |\n",
    "| **criterion** | Hàm đo độ không thuần khiết | 'gini', 'entropy' | • 'gini': Nhanh hơn<br>• 'entropy': Information gain |\n",
    "| **bootstrap** | Sampling với replacement | True/False | • True: Diversity trong training<br>• False: Sử dụng toàn bộ dataset |\n",
    "\n",
    "### 4.3.3 Gradient Boosting Parameters\n",
    "\n",
    "#### Core Parameters\n",
    "```python\n",
    "GradientBoostingClassifier(\n",
    "    n_estimators=100,        # Số boosting stages\n",
    "    learning_rate=0.1,       # Tốc độ học\n",
    "    max_depth=3,            # Độ sâu của weak learners\n",
    "    subsample=1.0,          # Fraction samples cho training\n",
    "    random_state=42\n",
    ")\n",
    "```\n",
    "\n",
    "**Giải thích chi tiết:**\n",
    "\n",
    "| Parameter | Ý nghĩa | Giá trị khuyến nghị | Tác động |\n",
    "|-----------|---------|-------------------|----------|\n",
    "| **n_estimators** | Số boosting rounds | 50-200 | • Nhiều: Có thể overfit nhưng accuracy cao<br>• Ít: Có thể underfit |\n",
    "| **learning_rate** | Shrinkage rate | 0.01-0.3 | • Thấp: Training chậm, cần nhiều estimators<br>• Cao: Training nhanh, dễ overfit |\n",
    "| **max_depth** | Độ sâu weak learner | 3-6 | • Shallow: Simple learners, tránh overfit<br>• Deep: Complex learners, có thể overfit |\n",
    "| **subsample** | Tỷ lệ samples training | 0.5-1.0 | • < 1.0: Stochastic gradient boosting<br>• = 1.0: Deterministic boosting |\n",
    "\n",
    "#### Advanced Parameters\n",
    "```python\n",
    "GradientBoostingClassifier(\n",
    "    loss='deviance',         # Loss function\n",
    "    min_samples_split=2,     # Min samples to split\n",
    "    min_samples_leaf=1,      # Min samples at leaf\n",
    "    max_features=None,       # Features to consider\n",
    "    validation_fraction=0.1, # Fraction for early stopping\n",
    "    n_iter_no_change=5      # Early stopping patience\n",
    ")\n",
    "```\n",
    "\n",
    "**Advanced Parameters Explained:**\n",
    "\n",
    "| Parameter | Ý nghĩa | Options | Tác động |\n",
    "|-----------|---------|---------|----------|\n",
    "| **loss** | Hàm loss | 'deviance', 'exponential' | • 'deviance': Logistic regression loss<br>• 'exponential': AdaBoost loss |\n",
    "| **validation_fraction** | Data cho early stopping | 0.1-0.2 | • Monitor overfitting<br>• Automatic stopping |\n",
    "| **warm_start** | Incremental training | True/False | • True: Có thể thêm estimators<br>• False: Training từ đầu |\n",
    "\n",
    "### 4.3.4 TF-IDF Vectorizer Parameters\n",
    "\n",
    "#### Core Parameters  \n",
    "```python\n",
    "TfidfVectorizer(\n",
    "    max_features=10000,      # Số features tối đa\n",
    "    ngram_range=(1, 2),      # N-gram range\n",
    "    min_df=2,               # Min document frequency\n",
    "    max_df=0.95,            # Max document frequency\n",
    "    stop_words='english'     # Stopwords removal\n",
    ")\n",
    "```\n",
    "\n",
    "**Giải thích chi tiết:**\n",
    "\n",
    "| Parameter | Ý nghĩa | Giá trị khuyến nghị | Tác động |\n",
    "|-----------|---------|-------------------|----------|\n",
    "| **max_features** | Số từ vựng tối đa | 5000-20000 | • Nhiều: Detailed representation, tốn memory<br>• Ít: Simple representation, fast |\n",
    "| **ngram_range** | Phạm vi n-grams | (1,1), (1,2), (1,3) | • (1,1): Unigrams only<br>• (1,2): Uni + bigrams<br>• (1,3): Uni + bi + trigrams |\n",
    "| **min_df** | Tần suất tối thiểu | 2-10 | • Cao: Loại bỏ rare words<br>• Thấp: Giữ lại nhiều words |\n",
    "| **max_df** | Tần suất tối đa | 0.8-0.95 | • Thấp: Loại bỏ common words<br>• Cao: Giữ lại most words |\n",
    "\n",
    "#### Advanced Parameters\n",
    "```python\n",
    "TfidfVectorizer(\n",
    "    sublinear_tf=True,       # Apply sublinear tf scaling\n",
    "    use_idf=True,           # Enable IDF weighting\n",
    "    smooth_idf=True,        # Smooth IDF weights\n",
    "    norm='l2',              # Normalization\n",
    "    analyzer='word',         # Level of analysis\n",
    "    token_pattern=r'\\b\\w+\\b' # Token pattern\n",
    ")\n",
    "```\n",
    "\n",
    "### 4.3.5 Parameter Tuning Strategies\n",
    "\n",
    "#### 4.3.5.1 Grid Search Strategy\n",
    "```python\n",
    "# Example parameter grid cho Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1.0, 10.0],\n",
    "    'solver': ['liblinear', 'lbfgs'],\n",
    "    'max_iter': [1000, 2000]\n",
    "}\n",
    "\n",
    "# Example parameter grid cho Random Forest  \n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "```\n",
    "\n",
    "#### 4.3.5.2 Validation Strategy\n",
    "```python\n",
    "# Cross-validation để tìm best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                    # 5-fold cross validation\n",
    "    scoring='accuracy',      # Optimization metric\n",
    "    n_jobs=-1               # Use all cores\n",
    ")\n",
    "```\n",
    "\n",
    "### 4.3.6 Parameter Selection Guidelines\n",
    "\n",
    "#### 4.3.6.1 For Small Datasets (< 5000 samples)\n",
    "- **Logistic Regression**: C=1.0, solver='liblinear'\n",
    "- **Random Forest**: n_estimators=50, max_depth=10\n",
    "- **Gradient Boosting**: n_estimators=50, learning_rate=0.1\n",
    "\n",
    "#### 4.3.6.2 For Medium Datasets (5000-20000 samples)  \n",
    "- **Logistic Regression**: C=1.0, solver='lbfgs'\n",
    "- **Random Forest**: n_estimators=100, max_depth=15\n",
    "- **Gradient Boosting**: n_estimators=100, learning_rate=0.1\n",
    "\n",
    "#### 4.3.6.3 For Large Datasets (> 20000 samples)\n",
    "- **Logistic Regression**: C=0.1, solver='lbfgs', max_iter=2000\n",
    "- **Random Forest**: n_estimators=200, max_depth=None\n",
    "- **Gradient Boosting**: n_estimators=150, learning_rate=0.05\n",
    "\n",
    "#### 4.3.6.4 Memory Optimization\n",
    "```python\n",
    "# Cho limited memory environments\n",
    "optimized_params = {\n",
    "    'tfidf_max_features': 5000,      # Reduce feature space\n",
    "    'rf_n_estimators': 50,           # Fewer trees\n",
    "    'gb_max_depth': 3,              # Shallow trees\n",
    "    'batch_size': 1000              # Process in batches\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bba28f",
   "metadata": {},
   "source": [
    "## 6. Chiến Lược Thực Thi Pipeline\n",
    "\n",
    "### 6.1 Pipeline Execution Strategy\n",
    "\n",
    "#### 6.1.1 Sequential Processing Approach\n",
    "```\n",
    "Data Loading → Preprocessing → Feature Engineering → Model Training → Evaluation\n",
    "     ↓              ↓               ↓                    ↓             ↓\n",
    "   Config         Config          Config            Config        Config\n",
    "   Driven         Driven          Driven            Driven        Driven\n",
    "```\n",
    "\n",
    "#### 6.1.2 Configuration-Driven Architecture\n",
    "\n",
    "**Ưu điểm của Config-Driven Approach:**\n",
    "- **Flexibility**: Dễ dàng thay đổi parameters mà không sửa code\n",
    "- **Reproducibility**: Mỗi experiment có config riêng, dễ reproduce\n",
    "- **Scalability**: Có thể chạy multiple configs song song\n",
    "- **Maintainability**: Tách biệt logic và configuration\n",
    "\n",
    "### 6.2 Memory và Performance Optimization\n",
    "\n",
    "#### 6.2.1 Data Loading Strategy\n",
    "```python\n",
    "# Trong LocalDataLoader/KaggleDataLoader\n",
    "Strategy: Lazy Loading + Chunked Processing\n",
    "- Load data theo batch để tiết kiệm memory\n",
    "- Sử dụng pandas.read_csv với chunksize cho large datasets\n",
    "- Immediate preprocessing để giảm memory footprint\n",
    "```\n",
    "\n",
    "#### 6.2.2 Text Processing Optimization\n",
    "```python\n",
    "# Trong PreProcessor\n",
    "Strategy: Pipeline Processing\n",
    "- Text cleaning → Tokenization → Normalization trong 1 pass\n",
    "- Sử dụng vectorized operations thay vì loops\n",
    "- Cache intermediate results cho repeated operations\n",
    "```\n",
    "\n",
    "#### 6.2.3 Feature Extraction Strategy\n",
    "```python\n",
    "# Trong TF-IDF Vectorizer  \n",
    "Strategy: Sparse Matrix + Memory Efficient\n",
    "- Sử dụng scipy.sparse matrices để tiết kiệm memory\n",
    "- Configurable max_features để control dimensionality\n",
    "- Batch processing cho large texts\n",
    "```\n",
    "\n",
    "### 6.3 Error Handling và Robustness\n",
    "\n",
    "#### 6.3.1 Graceful Error Handling\n",
    "- **Data Loading Errors**: Fallback từ Kaggle API sang local files\n",
    "- **Preprocessing Errors**: Skip corrupted texts, log warnings\n",
    "- **Training Errors**: Continue với other models nếu 1 model fail\n",
    "- **Memory Errors**: Automatic reduction của dataset size\n",
    "\n",
    "#### 6.3.2 Validation Strategy\n",
    "- **Config Validation**: Kiểm tra config format trước khi train\n",
    "- **Data Validation**: Kiểm tra data quality và format\n",
    "- **Model Validation**: Cross-validation để ensure stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ce0c2e",
   "metadata": {},
   "source": [
    "## 7. Design Patterns và Best Practices\n",
    "\n",
    "### 7.1 Architectural Design Patterns\n",
    "\n",
    "#### 7.1.1 Factory Pattern cho Model Creation\n",
    "```python\n",
    "# ModelTrainer.available_models dictionary\n",
    "\"logistic_regression\": LogisticRegressionAnalyzer,\n",
    "\"random_forest\": RandomForestAnalyzer,  \n",
    "\"gradient_boosting\": GradientBoostingAnalyzer\n",
    "\n",
    "# Dynamic model instantiation\n",
    "model_class = self.available_models[model_name]\n",
    "model = model_class()\n",
    "```\n",
    "\n",
    "**Lợi ích:**\n",
    "- Dễ dàng thêm models mới\n",
    "- Loose coupling giữa pipeline và specific models\n",
    "- Consistent interface cho tất cả models\n",
    "\n",
    "#### 7.1.2 Strategy Pattern cho Preprocessing\n",
    "```python\n",
    "# PreProcessor với multiple strategies\n",
    "def preprocess_for_sentiment(text, preserve_negation=True):\n",
    "    # Strategy có thể thay đổi based on use case\n",
    "    if preserve_negation:\n",
    "        return self._sentiment_aware_preprocessing(text)\n",
    "    else:\n",
    "        return self._standard_preprocessing(text)\n",
    "```\n",
    "\n",
    "#### 7.1.3 Template Method Pattern cho Training\n",
    "```python\n",
    "# Base workflow trong ModelTrainer\n",
    "def run_training_pipeline_with_configs():\n",
    "    1. Validate configs\n",
    "    2. For each model:\n",
    "       a. Load model with config\n",
    "       b. Train model  \n",
    "       c. Evaluate model\n",
    "       d. Save results\n",
    "    3. Compile results\n",
    "```\n",
    "\n",
    "### 7.2 Code Organization Best Practices\n",
    "\n",
    "#### 7.2.1 Separation of Concerns\n",
    "| Component | Responsibility | Single Purpose |\n",
    "|-----------|---------------|----------------|\n",
    "| **Data Loaders** | Data ingestion only | Load và basic format |\n",
    "| **PreProcessor** | Text cleaning only | Clean và normalize |\n",
    "| **Vectorizers** | Feature extraction only | Text → Numbers |\n",
    "| **Classifiers** | Model training only | Train và predict |\n",
    "| **ModelTrainer** | Orchestration only | Coordinate workflow |\n",
    "\n",
    "#### 7.2.2 Configuration Management\n",
    "```\n",
    "src/configs/\n",
    "├── accuracy_optimized_config.json    # High accuracy focus\n",
    "├── balanced_config.json              # Balanced approach  \n",
    "├── speed_optimized_config.json       # Fast training focus\n",
    "└── custom_config_template.json       # Template for new configs\n",
    "```\n",
    "\n",
    "#### 7.2.3 Modularity và Reusability\n",
    "- **Each classifier** là standalone module có thể dùng độc lập\n",
    "- **Common interfaces** để easy integration\n",
    "- **Configurable parameters** để flexible usage\n",
    "- **Error handling** tại mỗi level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f67ff",
   "metadata": {},
   "source": [
    "## 8. Scalability và Deployment Strategies\n",
    "\n",
    "### 8.1 Scalability Considerations\n",
    "\n",
    "#### 8.1.1 Horizontal Scaling Strategy\n",
    "```python\n",
    "# Multiple config files cho parallel processing\n",
    "configs = [\n",
    "    \"accuracy_optimized_config.json\",\n",
    "    \"balanced_config.json\", \n",
    "    \"speed_optimized_config.json\"\n",
    "]\n",
    "\n",
    "# Có thể chạy song song trên multiple machines/cores\n",
    "for config in configs:\n",
    "    run_training_pipeline(config)  # Independent execution\n",
    "```\n",
    "\n",
    "#### 8.1.2 Data Scaling Strategy\n",
    "```python\n",
    "# Configurable dataset sizes\n",
    "dataset_config = {\n",
    "    \"train_size\": [1000, 5000, 10000, 20000],  # Progressive scaling\n",
    "    \"test_size\": [100, 500, 1000, 2000],       # Proportional scaling\n",
    "    \"validation_split\": 0.2                    # Consistent validation\n",
    "}\n",
    "```\n",
    "\n",
    "#### 8.1.3 Model Scaling Strategy\n",
    "- **Progressive Training**: Start với small dataset → scale up\n",
    "- **Incremental Learning**: Update models với new data\n",
    "- **Ensemble Methods**: Combine multiple models cho better performance\n",
    "\n",
    "### 8.2 Production Deployment Strategy\n",
    "\n",
    "#### 8.2.1 Model Serialization\n",
    "```python\n",
    "# Standardized model saving\n",
    "model_artifacts = {\n",
    "    \"trained_model\": \"model.joblib\",           # Scikit-learn model\n",
    "    \"vectorizer\": \"vectorizer.joblib\",        # TF-IDF vectorizer  \n",
    "    \"preprocessor\": \"preprocessor.pickle\",    # Text preprocessor\n",
    "    \"config\": \"training_config.json\",        # Training configuration\n",
    "    \"metadata\": \"model_metadata.json\"        # Model information\n",
    "}\n",
    "```\n",
    "\n",
    "#### 8.2.2 Pipeline Deployment\n",
    "```python\n",
    "# Production pipeline structure\n",
    "class ProductionPipeline:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = load_model(model_path)\n",
    "        self.vectorizer = load_vectorizer(model_path)\n",
    "        self.preprocessor = load_preprocessor(model_path)\n",
    "    \n",
    "    def predict(self, text):\n",
    "        # Same preprocessing pipeline as training\n",
    "        cleaned_text = self.preprocessor.preprocess_for_sentiment(text)\n",
    "        features = self.vectorizer.transform([cleaned_text])\n",
    "        prediction = self.model.predict(features)\n",
    "        return prediction\n",
    "```\n",
    "\n",
    "#### 8.2.3 Monitoring và Maintenance\n",
    "- **Performance Monitoring**: Track accuracy over time\n",
    "- **Data Drift Detection**: Monitor input data changes\n",
    "- **Model Retraining**: Scheduled retraining với new data\n",
    "- **A/B Testing**: Compare model versions in production\n",
    "\n",
    "### 8.3 Future Enhancement Strategies\n",
    "\n",
    "#### 8.3.1 Advanced Techniques Integration\n",
    "- **Deep Learning Models**: BERT, RoBERTa integration\n",
    "- **Ensemble Methods**: Voting, stacking multiple models\n",
    "- **Feature Engineering**: Advanced NLP features (POS tags, named entities)\n",
    "- **Hyperparameter Optimization**: Automated tuning với Optuna/GridSearch\n",
    "\n",
    "#### 8.3.2 Infrastructure Improvements\n",
    "- **Containerization**: Docker cho consistent environments\n",
    "- **Cloud Deployment**: AWS/GCP/Azure deployment\n",
    "- **API Development**: REST API cho model serving\n",
    "- **CI/CD Pipeline**: Automated testing và deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7329513",
   "metadata": {},
   "source": [
    "## 9. Kết Luận và Khuyến Nghị\n",
    "\n",
    "### 9.1 Tổng Kết Chiến Lược Pipeline\n",
    "\n",
    "#### 9.1.1 Điểm Mạnh của Architecture\n",
    "✅ **Modular Design**: Mỗi component độc lập, dễ maintain và test  \n",
    "✅ **Configuration-Driven**: Flexible và easy to experiment  \n",
    "✅ **Error Handling**: Robust với graceful fallbacks  \n",
    "✅ **Scalable**: Có thể scale từ prototype đến production  \n",
    "✅ **Reproducible**: Consistent results với same configuration  \n",
    "\n",
    "#### 9.1.2 Workflow Efficiency\n",
    "- **Sequential Processing**: Clear data flow, easy to debug\n",
    "- **Batch Processing**: Memory efficient cho large datasets  \n",
    "- **Parallel Capability**: Multiple models có thể train độc lập\n",
    "- **Resource Management**: Optimal sử dụng memory và computation\n",
    "\n",
    "### 9.2 Best Practices Implemented\n",
    "\n",
    "#### 9.2.1 Software Engineering Principles\n",
    "| Principle | Implementation | Benefit |\n",
    "|-----------|---------------|---------|\n",
    "| **DRY (Don't Repeat Yourself)** | Shared base classes, common utilities | Reduced code duplication |\n",
    "| **SOLID Principles** | Single responsibility per class | Maintainable code |\n",
    "| **Separation of Concerns** | Each module has specific purpose | Clear architecture |\n",
    "| **Configuration Management** | JSON-based configs | Easy experimentation |\n",
    "\n",
    "#### 9.2.2 Data Science Best Practices\n",
    "- **Data Validation**: Input validation at each stage\n",
    "- **Feature Engineering**: Systematic text preprocessing\n",
    "- **Model Comparison**: Consistent evaluation metrics\n",
    "- **Experiment Tracking**: Detailed logging và results storage\n",
    "\n",
    "### 9.3 Khuyến Nghị cho Development\n",
    "\n",
    "#### 9.3.1 Short-term Improvements (1-2 tháng)\n",
    "1. **Add Cross-Validation**: K-fold validation cho robust evaluation\n",
    "2. **Hyperparameter Tuning**: Grid search hoặc random search\n",
    "3. **Feature Analysis**: Feature importance analysis\n",
    "4. **Performance Profiling**: Identify bottlenecks trong pipeline\n",
    "\n",
    "#### 9.3.2 Medium-term Enhancements (3-6 tháng)  \n",
    "1. **Deep Learning Integration**: Transformer models (BERT, RoBERTa)\n",
    "2. **Ensemble Methods**: Voting classifier combining all models\n",
    "3. **Real-time Processing**: Streaming data processing capability\n",
    "4. **A/B Testing Framework**: Compare multiple model versions\n",
    "\n",
    "#### 9.3.3 Long-term Vision (6-12 tháng)\n",
    "1. **MLOps Integration**: Full CI/CD pipeline với automated testing\n",
    "2. **Model Monitoring**: Production model performance tracking  \n",
    "3. **Auto-ML Capabilities**: Automated model selection và tuning\n",
    "4. **Multi-language Support**: Expand beyond English sentiment analysis\n",
    "\n",
    "### 9.4 Lessons Learned\n",
    "\n",
    "#### 9.4.1 Technical Insights\n",
    "- **Configuration-driven approach** significantly improves experimentation speed\n",
    "- **Modular architecture** makes debugging và maintenance easier\n",
    "- **Proper error handling** prevents pipeline crashes trong production\n",
    "- **Memory management** critical cho scalability\n",
    "\n",
    "#### 9.4.2 Process Insights  \n",
    "- **Early validation** của configs saves debugging time\n",
    "- **Consistent interfaces** giữa components reduces integration issues\n",
    "- **Comprehensive logging** essential cho troubleshooting\n",
    "- **Documentation** crucial cho team collaboration\n",
    "\n",
    "---\n",
    "\n",
    "## Tài Liệu Tham Khảo\n",
    "\n",
    "1. **Project Structure**: `/src/` directory với modular components\n",
    "2. **Configuration Examples**: `/src/configs/` với multiple strategy examples  \n",
    "3. **Model Implementations**: Individual classifier files với consistent interfaces\n",
    "4. **Pipeline Controller**: `main_modal_traning_focus.py` orchestrating entire workflow\n",
    "5. **Utility Modules**: Supporting modules cho preprocessing, vectorization, etc.\n",
    "\n",
    "---\n",
    "\n",
    "*Báo cáo này cung cấp comprehensive overview của pipeline strategy, focusing vào architectural decisions, implementation patterns, và best practices rather than specific performance metrics.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
