{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d874ffa",
   "metadata": {},
   "source": [
    "# Báo cáo tổng hợp: Phân tích hiệu năng 3 thuật toán học máy\n",
    "\n",
    "Notebook này tổng hợp, phân tích và so sánh hiệu năng của 3 thuật toán đã sử dụng trong dự án Amazon Reviews Sentiment Analysis:\n",
    "- Logistic Regression\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "\n",
    "Dữ liệu phân tích được lấy từ các kết quả thực nghiệm trong notebook model_performance_analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8aeee10",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Load Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b24c605f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(comprehensive_data)\n\u001b[32m     72\u001b[39m df_comprehensive = extract_comprehensive_data(reports_data)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m df_comprehensive[\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[43mdf_comprehensive\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UIT_workspace/Project_Python_For_AI/.venv/lib/python3.13/site-packages/pandas/core/frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/UIT_workspace/Project_Python_For_AI/.venv/lib/python3.13/site-packages/pandas/core/indexes/range.py:417\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    418\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'timestamp'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Load comprehensive performance data\n",
    "reports_dir = \"../src/reports/\"\n",
    "json_files = glob.glob(os.path.join(reports_dir, \"*.json\"))\n",
    "reports_data = []\n",
    "for file_path in sorted(json_files):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    data['file_info'] = {'filename': os.path.basename(file_path), 'filepath': file_path}\n",
    "    reports_data.append(data)\n",
    "\n",
    "def extract_comprehensive_data(reports_data):\n",
    "    comprehensive_data = []\n",
    "    for report in reports_data:\n",
    "        timestamp = report['training_summary']['timestamp']\n",
    "        filename = report['file_info']['filename']\n",
    "        training_info = {\n",
    "            'filename': filename,\n",
    "            'timestamp': timestamp,\n",
    "            'total_time_seconds': report['training_summary']['total_time_seconds'],\n",
    "            'train_dataset_size': report['training_summary']['train_dataset_size'],\n",
    "            'test_dataset_size': report['training_summary']['test_dataset_size']\n",
    "        }\n",
    "        for model_name, model_data in report['model_results'].items():\n",
    "            row = training_info.copy()\n",
    "            row.update({\n",
    "                'model_type': model_name,\n",
    "                'model_name_full': model_data['model_name'],\n",
    "                'train_accuracy': model_data['train_accuracy'],\n",
    "                'test_accuracy': model_data['test_accuracy'],\n",
    "                'overfitting_score': model_data['overfitting_score'],\n",
    "                'f1_macro': model_data['f1_macro'],\n",
    "                'f1_weighted': model_data['f1_weighted'],\n",
    "                'training_time': model_data['training_time'],\n",
    "                'tfidf_max_features': model_data['tfidf_params']['max_features'],\n",
    "                'tfidf_ngram_range': str(model_data['tfidf_params']['ngram_range']),\n",
    "                'tfidf_min_df': model_data['tfidf_params']['min_df'],\n",
    "                'tfidf_max_df': model_data['tfidf_params']['max_df'],\n",
    "                'tfidf_sublinear_tf': model_data['tfidf_params']['sublinear_tf'],\n",
    "            })\n",
    "            if model_name == 'logistic_regression':\n",
    "                row.update({\n",
    "                    'lr_C': model_data['model_params']['C'],\n",
    "                    'lr_max_iter': model_data['model_params']['max_iter'],\n",
    "                    'lr_solver': model_data['model_params']['solver']\n",
    "                })\n",
    "            elif model_name == 'random_forest':\n",
    "                row.update({\n",
    "                    'rf_n_estimators': model_data['model_params']['n_estimators'],\n",
    "                    'rf_max_depth': model_data['model_params']['max_depth'],\n",
    "                    'rf_min_samples_split': model_data['model_params']['min_samples_split'],\n",
    "                    'rf_max_features': model_data['model_params']['max_features']\n",
    "                })\n",
    "            elif model_name == 'gradient_boosting':\n",
    "                row.update({\n",
    "                    'gb_n_estimators': model_data['model_params']['n_estimators'],\n",
    "                    'gb_learning_rate': model_data['model_params']['learning_rate'],\n",
    "                    'gb_max_depth': model_data['model_params']['max_depth'],\n",
    "                    'gb_subsample': model_data['model_params']['subsample']\n",
    "                })\n",
    "            comprehensive_data.append(row)\n",
    "    return pd.DataFrame(comprehensive_data)\n",
    "\n",
    "df_comprehensive = extract_comprehensive_data(reports_data)\n",
    "df_comprehensive['datetime'] = pd.to_datetime(df_comprehensive['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6cd8d5",
   "metadata": {},
   "source": [
    "## 2. Algorithm Overview and Comparison\n",
    "\n",
    "| Thuật toán             | Đặc điểm chính | Ưu điểm | Nhược điểm |\n",
    "|-----------------------|----------------|---------|------------|\n",
    "| Logistic Regression   | Tuyến tính, giải thích tốt, nhanh | Đơn giản, dễ triển khai, ít overfit | Hiệu năng thấp với dữ liệu phi tuyến |\n",
    "| Random Forest         | Ensemble, nhiều cây quyết định | Chống overfit tốt, xử lý phi tuyến | Chậm, khó giải thích, tốn tài nguyên |\n",
    "| Gradient Boosting     | Boosting, học tuần tự | Hiệu năng cao, tối ưu tốt | Dễ overfit, nhạy cảm tham số, chậm |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffcfcd0",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression Analysis and Results\n",
    "\n",
    "- Phân tích ảnh hưởng tham số C, solver, max_iter\n",
    "- Đánh giá độ hội tụ và độ ổn định\n",
    "- Hiệu năng thực tế trên tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed64bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_data = df_comprehensive[df_comprehensive['model_type'] == 'logistic_regression']\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(data=lr_data, x='datetime', y='test_accuracy', marker='o')\n",
    "plt.title('Logistic Regression - Test Accuracy Over Time')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xlabel('Time')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=lr_data, x='lr_C', y='test_accuracy')\n",
    "plt.title('Impact of C Parameter on Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3726882c",
   "metadata": {},
   "source": [
    "## 4. Random Forest Analysis and Results\n",
    "\n",
    "- Phân tích hiệu ứng ensemble, tham số n_estimators, max_depth, min_samples_split\n",
    "- Đánh giá feature importance và overfitting\n",
    "- Biến động hiệu năng theo cấu hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_data = df_comprehensive[df_comprehensive['model_type'] == 'random_forest']\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(data=rf_data, x='datetime', y='test_accuracy', marker='o')\n",
    "plt.title('Random Forest - Test Accuracy Over Time')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xlabel('Time')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=rf_data, x='rf_n_estimators', y='test_accuracy')\n",
    "plt.title('Impact of n_estimators on Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1964e886",
   "metadata": {},
   "source": [
    "## 5. Gradient Boosting Analysis and Results\n",
    "\n",
    "- Phân tích ảnh hưởng learning_rate, số vòng boosting, độ sâu cây\n",
    "- Đánh giá thời gian huấn luyện và hiệu năng\n",
    "- Xác định tham số tối ưu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_data = df_comprehensive[df_comprehensive['model_type'] == 'gradient_boosting']\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(data=gb_data, x='datetime', y='test_accuracy', marker='o')\n",
    "plt.title('Gradient Boosting - Test Accuracy Over Time')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xlabel('Time')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(data=gb_data, x='gb_learning_rate', y='test_accuracy')\n",
    "plt.title('Impact of Learning Rate on Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e48ddf4",
   "metadata": {},
   "source": [
    "## 6. Cross-Algorithm Performance Comparison\n",
    "\n",
    "So sánh trực tiếp các thuật toán về accuracy, F1-score, thời gian huấn luyện, độ ổn định và xu hướng overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26599210",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=df_comprehensive, x='model_type', y='test_accuracy')\n",
    "plt.title('Test Accuracy Comparison Across Algorithms')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(data=df_comprehensive, x='model_type', y='f1_macro')\n",
    "plt.title('F1 Macro Score Comparison Across Algorithms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513bfb91",
   "metadata": {},
   "source": [
    "## 7. Parameter Impact Analysis Across Algorithms\n",
    "\n",
    "Phân tích ảnh hưởng của các tham số TF-IDF (max_features, ngram_range, min_df, max_df) lên từng thuật toán. Trực quan hóa bằng heatmap và correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af53793",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_pivot = df_comprehensive.pivot_table(values='test_accuracy', index='model_type', columns='tfidf_max_features', aggfunc='mean')\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(perf_pivot, annot=True, fmt='.3f', cmap='RdYlGn')\n",
    "plt.title('Test Accuracy by Model & TF-IDF max_features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965aa035",
   "metadata": {},
   "source": [
    "## 8. Best Configuration Recommendations\n",
    "\n",
    "Bảng tổng hợp các cấu hình tối ưu cho từng thuật toán dựa trên các tiêu chí: accuracy, F1-score, balanced performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_configs(df):\n",
    "    bests = {}\n",
    "    for model in df['model_type'].unique():\n",
    "        data = df[df['model_type'] == model]\n",
    "        best_acc = data.loc[data['test_accuracy'].idxmax()]\n",
    "        best_f1 = data.loc[data['f1_macro'].idxmax()]\n",
    "        balanced = data.copy()\n",
    "        balanced['balanced_score'] = balanced['test_accuracy'] - balanced['overfitting_score']\n",
    "        best_bal = balanced.loc[balanced['balanced_score'].idxmax()]\n",
    "        bests[model] = {\n",
    "            'accuracy': best_acc,\n",
    "            'f1': best_f1,\n",
    "            'balanced': best_bal\n",
    "        }\n",
    "    return bests\n",
    "\n",
    "best_configs = get_best_configs(df_comprehensive)\n",
    "for model, configs in best_configs.items():\n",
    "    print(f\"\\nModel: {model}\")\n",
    "    print(f\"  Best Accuracy: {configs['accuracy']['test_accuracy']:.4f} | Params: {configs['accuracy']}\")\n",
    "    print(f\"  Best F1: {configs['f1']['f1_macro']:.4f} | Params: {configs['f1']}\")\n",
    "    print(f\"  Best Balanced: {configs['balanced']['balanced_score']:.4f} | Params: {configs['balanced']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93a446a",
   "metadata": {},
   "source": [
    "## 9. Algorithm Selection Guidelines\n",
    "\n",
    "- Nếu dữ liệu tuyến tính, cần giải thích: Logistic Regression\n",
    "- Nếu dữ liệu phức tạp, nhiều đặc trưng, cần chống overfit: Random Forest\n",
    "- Nếu cần tối ưu hóa hiệu năng, chấp nhận tuning tham số: Gradient Boosting\n",
    "\n",
    "### Decision Tree for Algorithm Selection\n",
    "\n",
    "```mermaid\n",
    "graph TD;\n",
    "    A[Start] --> B{Dữ liệu tuyến tính?}\n",
    "    B -- Có --> C[Logistic Regression]\n",
    "    B -- Không --> D{Cần chống overfit?}\n",
    "    D -- Có --> E[Random Forest]\n",
    "    D -- Không --> F[Gradient Boosting]\n",
    "```\n",
    "\n",
    "### Tổng kết\n",
    "- Logistic Regression: Đơn giản, nhanh, phù hợp dữ liệu tuyến tính\n",
    "- Random Forest: Chống overfit tốt, phù hợp dữ liệu phức tạp\n",
    "- Gradient Boosting: Hiệu năng cao, cần tuning kỹ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
