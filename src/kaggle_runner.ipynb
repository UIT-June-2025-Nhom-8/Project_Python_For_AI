{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:49:09.737389Z",
     "iopub.status.busy": "2025-08-21T17:49:09.736959Z",
     "iopub.status.idle": "2025-08-21T17:49:09.751878Z",
     "shell.execute_reply": "2025-08-21T17:49:09.750508Z",
     "shell.execute_reply.started": "2025-08-21T17:49:09.737366Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amazon-reviews/amazon_review_polarity_csv.tgz\n",
      "/kaggle/input/amazon-reviews/train.csv\n",
      "/kaggle/input/amazon-reviews/test.csv\n",
      "/kaggle/input/d/ducleathome/modules/pre_processor.py\n",
      "/kaggle/input/d/ducleathome/modules/text_analyzer.py\n",
      "/kaggle/input/d/ducleathome/modules/random_forest_classifier.py\n",
      "/kaggle/input/d/ducleathome/modules/config_loader.py\n",
      "/kaggle/input/d/ducleathome/modules/stopwords_config.py\n",
      "/kaggle/input/d/ducleathome/modules/logistic_regression_classifier.py\n",
      "/kaggle/input/d/ducleathome/modules/model_trainer.py\n",
      "/kaggle/input/d/ducleathome/modules/kaggle_data_loader.py\n",
      "/kaggle/input/d/ducleathome/modules/accuracy_optimized_config_2.json\n",
      "/kaggle/input/d/ducleathome/modules/tf_idf_vectorizer.py\n",
      "/kaggle/input/d/ducleathome/modules/accuracy_optimized_config.json\n",
      "/kaggle/input/d/ducleathome/modules/balanced_config.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:49:09.754137Z",
     "iopub.status.busy": "2025-08-21T17:49:09.753707Z",
     "iopub.status.idle": "2025-08-21T17:49:09.759134Z",
     "shell.execute_reply": "2025-08-21T17:49:09.758139Z",
     "shell.execute_reply.started": "2025-08-21T17:49:09.754114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:49:09.760492Z",
     "iopub.status.busy": "2025-08-21T17:49:09.760234Z",
     "iopub.status.idle": "2025-08-21T17:49:09.781442Z",
     "shell.execute_reply": "2025-08-21T17:49:09.780333Z",
     "shell.execute_reply.started": "2025-08-21T17:49:09.760472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from kaggle_data_loader import KaggleDataLoader\n",
    "    from config_loader import load_json_config\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Use Kaggle-optimized preprocessor\n",
    "    from preprocessor_kaggle import KagglePreProcessor\n",
    "    \n",
    "    from model_trainer import ModelTrainer\n",
    "    print(\"‚úÖ All modules imported successfully\")\n",
    "    print(\"üèÜ Using Kaggle-optimized preprocessor with lazy initialization\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"Make sure all required modules are in the path\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:49:09.784163Z",
     "iopub.status.busy": "2025-08-21T17:49:09.783836Z",
     "iopub.status.idle": "2025-08-21T17:49:09.803913Z",
     "shell.execute_reply": "2025-08-21T17:49:09.802850Z",
     "shell.execute_reply.started": "2025-08-21T17:49:09.784139Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "CONFIG_PATH = \"/kaggle/input/d/ducleathome/modules/accuracy_optimized_config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T17:49:09.805100Z",
     "iopub.status.busy": "2025-08-21T17:49:09.804817Z",
     "iopub.status.idle": "2025-08-21T17:49:09.827724Z",
     "shell.execute_reply": "2025-08-21T17:49:09.826701Z",
     "shell.execute_reply.started": "2025-08-21T17:49:09.805079Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded from: /kaggle/input/d/ducleathome/modules/accuracy_optimized_config.json\n"
     ]
    }
   ],
   "source": [
    "# Load configuration with proper path\n",
    "config = load_json_config(str(CONFIG_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79fc78b1-c4f3-4c08-b262-7ecc31e138b0",
    "_uuid": "9817cdd1-602f-4a1d-a14b-268c87bf6f03",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-21T17:49:09.829374Z",
     "iopub.status.busy": "2025-08-21T17:49:09.829056Z",
     "iopub.status.idle": "2025-08-21T17:49:37.068741Z",
     "shell.execute_reply": "2025-08-21T17:49:37.067741Z",
     "shell.execute_reply.started": "2025-08-21T17:49:09.829351Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Kaggle Amazon reviews dataset...\n",
      "KaggleHub download path: /kaggle/input/amazon-reviews\n",
      "\n",
      "=== LOADING DATA ===\n",
      "Successfully loaded data:\n",
      "   - Train: (3599999, 3)\n",
      "   - Test: (399999, 3)\n",
      "\n",
      "=== DATA VALIDATION ===\n",
      "Initial Train data info:\n",
      "   - Shape: (3599999, 3)\n",
      "Initial Test data info:\n",
      "   - Shape: (399999, 3)\n",
      "\n",
      "Initial label distribution:\n",
      "   Training: {1: 1800000, 2: 1799999}\n",
      "   Test: {1: 200000, 2: 199999}\n",
      "All labels are within expected range [1, 2]\n",
      "Initial data validation completed\n",
      "\n",
      "=== APPLYING SIZE LIMITS ===\n",
      "Size limits applied:\n",
      "   Training: 3599999 -> 200000 samples\n",
      "   Test: 399999 -> 20000 samples\n",
      "\n",
      "=== DATA COMBINATION ===\n",
      "Analyzing content availability...\n",
      "   Training - Empty titles: 18, Empty texts: 0, Both empty: 0\n",
      "   Test - Empty titles: 3, Empty texts: 0, Both empty: 0\n",
      "Combining title and text columns...\n",
      "Data combination completed:\n",
      "   Training: (200000, 2)\n",
      "   Test: (20000, 2)\n",
      "   Average input length - Train: 440.0, Test: 440.7\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    # \"train_size\": config.get(\"dataset_config\", {}).get(\"train_size\", 1000),\n",
    "    # \"test_size\": config.get(\"dataset_config\", {}).get(\"test_size\", 100),\n",
    "    \"train_size\": 1000,\n",
    "    \"test_size\": 100,\n",
    "}\n",
    "\n",
    "data_loader = KaggleDataLoader(config)\n",
    "train_df, test_df = data_loader.prepare_dataframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üì• SETUP OPTIMIZED STOPWORDS FOR SENTIMENT ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "from stopwords_provider_kaggle import StopwordsProviderKaggle\n",
    "\n",
    "# Initialize stopwords provider (handles all downloads automatically)\n",
    "kaggle_stopwords_manager = StopwordsProviderKaggle()\n",
    "\n",
    "# Get optimized stopwords (automatic setup: cache check ‚Üí download if needed ‚Üí optimize)\n",
    "custom_stopwords = kaggle_stopwords_manager.get_stopwords()\n",
    "\n",
    "print(f\"‚úÖ Stopwords ready! Total: {len(custom_stopwords)} words\")\n",
    "print(\"üöÄ Optimized for Amazon reviews sentiment analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üîß INITIALIZE KAGGLE PREPROCESSOR\n",
    "# =============================================================================\n",
    "\n",
    "# Initialize the Kaggle preprocessor with the optimized stopwords\n",
    "preprocessor = KagglePreProcessor()\n",
    "preprocessor.initialize(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üìä SMART PREPROCESSING WITH SAVE/LOAD FUNCTIONALITY\n",
    "# =============================================================================\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "preprocessing_needed = True\n",
    "PREPROCESSED_DATA_PATH = \"/kaggle/working/preprocessed_data.pkl\"\n",
    "\n",
    "# Try to load existing preprocessed data first\n",
    "if os.path.exists(PREPROCESSED_DATA_PATH):\n",
    "    try:\n",
    "        print(\"üìÇ Loading existing preprocessed data...\")\n",
    "        with open(PREPROCESSED_DATA_PATH, 'rb') as f:\n",
    "            preprocessed_data = pickle.load(f)\n",
    "            train_df = preprocessed_data['train_df']\n",
    "            test_df = preprocessed_data['test_df']\n",
    "        \n",
    "        print(f\"‚úÖ Preprocessed data loaded successfully!\")\n",
    "        print(f\"   Train shape: {train_df.shape}\")\n",
    "        print(f\"   Test shape: {test_df.shape}\")\n",
    "        \n",
    "        # Skip fresh preprocessing since we loaded existing data\n",
    "        preprocessing_needed = False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading preprocessed data: {e}\")\n",
    "        print(\"üîÑ Will run preprocessing from scratch...\")\n",
    "        preprocessing_needed = True\n",
    "else:\n",
    "    print(\"üîÑ No existing preprocessed data found or loading disabled\")\n",
    "    preprocessing_needed = True\n",
    "\n",
    "# Run test data preprocessing if needed (train data already processed above)\n",
    "if preprocessing_needed:\n",
    "    print(\"üîÑ Running test data preprocessing...\")\n",
    "    \n",
    "    # Preprocess test data with the same pipeline as train data\n",
    "    test_df = preprocessor.clean_data(test_df)\n",
    "    test_df = preprocessor.remove_duplicates(test_df)\n",
    "    test_df = test_df.assign(\n",
    "        normalized_input=test_df[\"input\"].apply(\n",
    "            lambda x: preprocessor.preprocess_for_sentiment(x)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Test data preprocessing completed!\")\n",
    "    \n",
    "    # Save preprocessed data for future use\n",
    "    if test_df is not None and train_df is not None:\n",
    "        try:\n",
    "            preprocessed_data = {\n",
    "                'train_df': train_df,\n",
    "                'test_df': test_df,\n",
    "                'preprocessing_info': {\n",
    "                    'train_shape': train_df.shape,\n",
    "                    'test_shape': test_df.shape,\n",
    "                    'columns': train_df.columns.tolist()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            with open(PREPROCESSED_DATA_PATH, 'wb') as f:\n",
    "                pickle.dump(preprocessed_data, f)\n",
    "            \n",
    "            print(f\"üíæ Preprocessed data saved to: {PREPROCESSED_DATA_PATH}\")\n",
    "            print(\"   Next runs can load this data to save time!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving preprocessed data: {e}\")\n",
    "    else:\n",
    "        print(\"‚ùå Preprocessed data is incomplete\")\n",
    "        raise ValueError(\"Preprocessed data is incomplete, cannot save.\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate preprocessed data\n",
    "print(f\"Train data shape: {train_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "print(f\"Train data columns: {train_df.columns.tolist()}\")\n",
    "print(f\"Missing values in train: {train_df.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in test: {test_df.isnull().sum().sum()}\")\n",
    "\n",
    "# Check unique labels\n",
    "print(f\"Unique labels in train: {train_df['label'].unique()}\")\n",
    "print(f\"Label distribution in train:\\n{train_df['label'].value_counts()}\")\n",
    "\n",
    "# Sample of preprocessed text\n",
    "print(\"\\nSample preprocessed texts:\")\n",
    "for i in range(3):\n",
    "    print(f\"Original: {train_df.iloc[i]['input'][:100]}...\")\n",
    "    print(f\"Processed: {train_df.iloc[i]['normalized_input'][:100]}...\")\n",
    "    print(f\"Label: {train_df.iloc[i]['label']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üéØ KAGGLE RUNNER CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Select which models to train (set to True to train, False to skip)\n",
    "MODEL_SELECTION = {\n",
    "    'logistic_regression': True,    # Fast baseline model\n",
    "    'random_forest': True,         # Ensemble method  \n",
    "    'gradient_boosting': True      # Advanced boosting\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ModelTrainer with preprocessed data\n",
    "trainer = ModelTrainer(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    text_column='normalized_input',  # Use preprocessed text\n",
    "    label_column='label',\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ModelTrainer initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ü§ñ MODEL TRAINING - LOGISTIC REGRESSION\n",
    "# =============================================================================\n",
    "\n",
    "logistic_results = None\n",
    "\n",
    "if MODEL_SELECTION['logistic_regression']:\n",
    "    print(\"üöÄ Training Logistic Regression Model...\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        logistic_results = trainer.train_logistic_regression()\n",
    "        \n",
    "        print(f\"‚úÖ Logistic Regression Training Completed!\")\n",
    "        print(f\"üìä Training Accuracy: {logistic_results['train_accuracy']:.4f}\")\n",
    "        print(f\"üìä Validation Accuracy: {logistic_results['test_accuracy']:.4f}\")\n",
    "        print(f\"üìä F1 Score: {logistic_results['f1_score']:.4f}\")\n",
    "        print(f\"üíæ Model saved to: {logistic_results['model_path']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error training Logistic Regression: {str(e)}\")\n",
    "        logistic_results = None\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Logistic Regression training SKIPPED (disabled in config)\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üå≤ MODEL TRAINING - RANDOM FOREST\n",
    "# =============================================================================\n",
    "\n",
    "forest_results = None\n",
    "\n",
    "if MODEL_SELECTION['random_forest']:\n",
    "    print(\"üöÄ Training Random Forest Model...\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        forest_results = trainer.train_random_forest()\n",
    "        \n",
    "        print(f\"‚úÖ Random Forest Training Completed!\")\n",
    "        print(f\"üìä Training Accuracy: {forest_results['train_accuracy']:.4f}\")\n",
    "        print(f\"üìä Validation Accuracy: {forest_results['test_accuracy']:.4f}\")\n",
    "        print(f\"üìä F1 Score: {forest_results['f1_score']:.4f}\")\n",
    "        print(f\"üíæ Model saved to: {forest_results['model_path']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error training Random Forest: {str(e)}\")\n",
    "        forest_results = None\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Random Forest training SKIPPED (disabled in config)\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ‚ö° MODEL TRAINING - GRADIENT BOOSTING\n",
    "# =============================================================================\n",
    "\n",
    "gb_results = None\n",
    "\n",
    "if MODEL_SELECTION['gradient_boosting']:\n",
    "    print(\"üöÄ Training Gradient Boosting Model...\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        gb_results = trainer.train_gradient_boosting()\n",
    "        \n",
    "        print(f\"‚úÖ Gradient Boosting Training Completed!\")\n",
    "        print(f\"üìä Training Accuracy: {gb_results['train_accuracy']:.4f}\")\n",
    "        print(f\"üìä Validation Accuracy: {gb_results['test_accuracy']:.4f}\")\n",
    "        print(f\"üìä F1 Score: {gb_results['f1_score']:.4f}\")\n",
    "        print(f\"üíæ Model saved to: {gb_results['model_path']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error training Gradient Boosting: {str(e)}\")\n",
    "        gb_results = None\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Gradient Boosting training SKIPPED (disabled in config)\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üìà TRAINING SUMMARY & RESULTS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìà TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results_summary = []\n",
    "trained_models = 0\n",
    "skipped_models = 0\n",
    "\n",
    "# Collect results from successfully trained models\n",
    "if logistic_results:\n",
    "    results_summary.append({\n",
    "        'Model': 'Logistic Regression',\n",
    "        'Train Accuracy': logistic_results['train_accuracy'],\n",
    "        'Test Accuracy': logistic_results['test_accuracy'],\n",
    "        'F1 Score': logistic_results['f1_score'],\n",
    "        'Model Path': logistic_results['model_path']\n",
    "    })\n",
    "    trained_models += 1\n",
    "elif MODEL_SELECTION['logistic_regression']:\n",
    "    print(\"‚ùå Logistic Regression: Failed to train\")\n",
    "else:\n",
    "    skipped_models += 1\n",
    "\n",
    "if forest_results:\n",
    "    results_summary.append({\n",
    "        'Model': 'Random Forest',\n",
    "        'Train Accuracy': forest_results['train_accuracy'],\n",
    "        'Test Accuracy': forest_results['test_accuracy'],\n",
    "        'F1 Score': forest_results['f1_score'],\n",
    "        'Model Path': forest_results['model_path']\n",
    "    })\n",
    "    trained_models += 1\n",
    "elif MODEL_SELECTION['random_forest']:\n",
    "    print(\"‚ùå Random Forest: Failed to train\")\n",
    "else:\n",
    "    skipped_models += 1\n",
    "\n",
    "if gb_results:\n",
    "    results_summary.append({\n",
    "        'Model': 'Gradient Boosting',\n",
    "        'Train Accuracy': gb_results['train_accuracy'],\n",
    "        'Test Accuracy': gb_results['test_accuracy'],\n",
    "        'F1 Score': gb_results['f1_score'],\n",
    "        'Model Path': gb_results['model_path']\n",
    "    })\n",
    "    trained_models += 1\n",
    "elif MODEL_SELECTION['gradient_boosting']:\n",
    "    print(\"‚ùå Gradient Boosting: Failed to train\")\n",
    "else:\n",
    "    skipped_models += 1\n",
    "\n",
    "print(f\"\\nüìä Training Statistics:\")\n",
    "print(f\"   ‚úÖ Successfully trained: {trained_models} models\")\n",
    "print(f\"   ‚è≠Ô∏è  Skipped: {skipped_models} models\")\n",
    "print(f\"   ‚ùå Failed: {3 - trained_models - skipped_models} models\")\n",
    "\n",
    "# Display results table if any models were trained\n",
    "if results_summary:\n",
    "    import pandas as pd\n",
    "    summary_df = pd.DataFrame(results_summary)\n",
    "    print(\"\\nüìä Model Performance Comparison:\")\n",
    "    print(summary_df.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # Find best model\n",
    "    if len(results_summary) > 1:\n",
    "        best_model = summary_df.loc[summary_df['Test Accuracy'].idxmax()]\n",
    "        print(f\"\\nüèÜ Best Model: {best_model['Model']}\")\n",
    "        print(f\"   Test Accuracy: {best_model['Test Accuracy']:.4f}\")\n",
    "        print(f\"   F1 Score: {best_model['F1 Score']:.4f}\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ Single model trained: {results_summary[0]['Model']}\")\n",
    "        print(f\"   Test Accuracy: {results_summary[0]['Test Accuracy']:.4f}\")\n",
    "        print(f\"   F1 Score: {results_summary[0]['F1 Score']:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå No models were successfully trained!\")\n",
    "    print(\"üí° Check your model selection configuration and try again.\")\n",
    "\n",
    "print(\"\\n‚úÖ Training pipeline completed!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Save training summary to file (for Kaggle output)\n",
    "if results_summary:\n",
    "    import json\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Create summary for saving\n",
    "    training_summary = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'dataset_info': {\n",
    "            'train_size': len(train_df),\n",
    "            'test_size': len(test_df),\n",
    "            'train_distribution': train_df['label'].value_counts().to_dict(),\n",
    "        },\n",
    "        'models': results_summary,\n",
    "        'config_used': CONFIG_PATH\n",
    "    }\n",
    "    \n",
    "    # Save to JSON file\n",
    "    summary_file = '/kaggle/working/training_summary.json'\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(training_summary, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"üìÑ Training summary saved to: {summary_file}\")\n",
    "    \n",
    "    # Also save as CSV for easy viewing\n",
    "    csv_file = '/kaggle/working/model_comparison.csv'\n",
    "    summary_df.to_csv(csv_file, index=False)\n",
    "    print(f\"üìä Model comparison saved to: {csv_file}\")\n",
    "    \n",
    "print(\"\\nüéâ All tasks completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1340369,
     "isSourceIdPinned": false,
     "sourceId": 2233682,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8081345,
     "sourceId": 12829867,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
